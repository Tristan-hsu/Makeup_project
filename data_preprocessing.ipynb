{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepocessing\n",
    "1. Use mediapipe to draw eye region shape with only black and white color.\n",
    "2. Use mediapipe to draw trimap, which means white, gray, and black color to distinguish foreground, blurred contour part and background, based on previous image to position the make-up region.\n",
    "3. Use Pymatting with trimap and original image to find make-up region.\n",
    "4. As result, step 1 figure will be independent variable x and step 3 figure will be dependent variable y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Load image using OpenCV\n",
    "silhouette =  [\n",
    "    10,  338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,\n",
    "    397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,\n",
    "    172, 58,  132, 93,  234, 127, 162, 21,  54,  103, 67,  109\n",
    "  ]\n",
    "\n",
    "\n",
    "rightEyeUpper0 =  [246, 161, 160, 159, 158, 157, 173]\n",
    "rightEyeUpper1 = [247, 30, 29, 27, 28, 56, 190]\n",
    "rightEyeLower0 = [33, 7, 163, 144, 145, 153, 154, 155, 133]\n",
    "rightEyeLower1 = [130, 25, 110, 24, 23, 22, 26, 112, 243]\n",
    "rightEyeLower3 = [143, 111, 117, 118, 119, 120, 121, 128, 245]\n",
    "rightEyebrowLower = [ 124, 46, 53, 52, 65, 193]\n",
    "\n",
    "leftEyeUpper0 = [466, 388, 387, 386, 385, 384, 398]\n",
    "leftEyeUpper1 = [467, 260, 259, 257, 258, 286, 414]\n",
    "leftEyeLower0 = [263, 249, 390, 373, 374, 380, 381, 382, 362]\n",
    "leftEyeLower1 = [359, 255, 339, 254, 253, 252, 256, 341, 463]\n",
    "leftEyeLower3 = [372, 340, 346, 347, 348, 349, 350, 357, 465]\n",
    "\n",
    "rightEyeLower0.reverse()\n",
    "rightEyeLower1.reverse()\n",
    "rightEyeLower3.reverse()\n",
    "leftEyeLower0.reverse()\n",
    "leftEyeLower1.reverse()\n",
    "leftEyeLower3.reverse()\n",
    "\n",
    "leftEyebrowLower = [276, 283, 282, 295, 285]\n",
    "\n",
    "\n",
    "\n",
    "# Replace with your image path\n",
    "# Defien all original settings\n",
    "\n",
    "def eye_region_generator(image,index, region_type: str, image_output_path:str):\n",
    "    \n",
    "    righteyeout_position = []\n",
    "    righteyein_position = []\n",
    "    lefteyeout_position = []\n",
    "    lefteyein_position = []\n",
    "    righteyemargin_position = []\n",
    "    lefteyemargin_position = []\n",
    "    # Convert the BGR image to RGB\n",
    "    height, width, _ = image.shape\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image to find facial landmarks\n",
    "    results = face_mesh.process(rgb_image)\n",
    "\n",
    "    # Check if landmarks were detected\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Draw facial landmarks on the image\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "            # Right Eye out region\n",
    "            for i in rightEyebrowLower+rightEyeLower3:\n",
    "                lm = face_landmarks.landmark[i]\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                righteyeout_position.append([x,y])\n",
    "            righteyeout_position = np.array(righteyeout_position, dtype=np.int32).reshape((-1, 1, 2))\n",
    "            \n",
    "            # Right Eye margin region        \n",
    "            for i in rightEyeUpper1+rightEyeLower1:\n",
    "                lm = face_landmarks.landmark[i]\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                righteyemargin_position.append([x,y])\n",
    "            righteyemargin_position = np.array(righteyemargin_position, dtype=np.int32).reshape((-1, 1, 2))\n",
    "            cv2.fillPoly(image, [righteyemargin_position],(255,255,255))  \n",
    "            \n",
    "            # Right Eye in region\n",
    "            for i in rightEyeLower0+rightEyeUpper0:\n",
    "                lm = face_landmarks.landmark[i]\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                righteyein_position.append([x,y])\n",
    "            righteyein_position = np.array(righteyein_position, dtype=np.int32).reshape((-1, 1, 2))        \n",
    "            cv2.fillPoly(image, [righteyein_position],(0, 0, 0))      \n",
    "                    \n",
    "            # Left Eye out region\n",
    "            for i in leftEyebrowLower+leftEyeLower3:\n",
    "                lm = face_landmarks.landmark[i]\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                lefteyeout_position.append([x,y])\n",
    "            lefteyeout_position = np.array(lefteyeout_position, dtype=np.int32).reshape((-1, 1, 2))\n",
    "            \n",
    "            # Left Eye margin region        \n",
    "            for i in leftEyeUpper1+leftEyeLower1:\n",
    "                lm = face_landmarks.landmark[i]\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                lefteyemargin_position.append([x,y])\n",
    "            lefteyemargin_position = np.array(lefteyemargin_position, dtype=np.int32).reshape((-1, 1, 2))\n",
    "            cv2.fillPoly(image, [lefteyemargin_position],(255,255,255))        \n",
    "            \n",
    "            # Left Eye in region\n",
    "            for i in leftEyeLower0+leftEyeUpper0:\n",
    "                lm = face_landmarks.landmark[i]\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                lefteyein_position.append([x,y])\n",
    "            lefteyein_position = np.array(lefteyein_position, dtype=np.int32).reshape((-1, 1, 2))        \n",
    "            cv2.fillPoly(image, [lefteyein_position],(0, 0, 0))       \n",
    "        \n",
    "            # Create a mask of the same size as the image, filled with zeros (black)\n",
    "            \n",
    "            mask = np.zeros_like(image)\n",
    "            \n",
    "\n",
    "            # # Fill the right eyebrow lower position on the mask with white color\n",
    "            cv2.fillPoly(mask, [righteyeout_position], (255, 255, 255))\n",
    "            cv2.fillPoly(mask, [lefteyeout_position], (255, 255, 255))\n",
    "            # # Apply the inverted mask to the image\n",
    "            image = cv2.bitwise_and(image, mask)        \n",
    "                \n",
    "            # Create mask2 to cover the image on color not black or white\n",
    "            mask2 = None\n",
    "            mask2 = np.zeros_like(image)\n",
    "            # Create condition for non-black and non-white pixels\n",
    "            condition = (image != [0, 0, 0])\n",
    "            condition2 = (image == [255, 255, 255])\n",
    "            condition = condition.all(axis=-1)\n",
    "            condition2 = condition2.all(axis=-1)\n",
    "            \n",
    "            if region_type == 'allblackwhite':\n",
    "                mask2[condition] = [255,255,255]\n",
    "            elif region_type == 'trimap':\n",
    "                mask2[condition] = [128,128,128]\n",
    "            index = str(index)\n",
    "            mask2[condition2] = [255,255,255]\n",
    "            inverted_allblackwhite = cv2.bitwise_not(mask2)      \n",
    "            image = cv2.bitwise_and(image, inverted_allblackwhite)        \n",
    "            output_image_path = os.path.join(image_output_path, index)\n",
    "            cv2.imwrite(output_image_path, mask2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '256img_lst' \n",
    "imagelist = os.listdir(image_path)\n",
    "\n",
    "for index in imagelist:\n",
    "    image = cv2.imread(image_path+'/'+ index)\n",
    "    eye_region_generator(image,index,'allblackwhite','allblackwhite1')\n",
    "    eye_region_generator(image,index,'trimap','trimap1')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "face_mesh.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "Use Pymatting. Choose to use rw algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trimap1/038.jpg file has problem\n",
      "./trimap1/213.jpg file has problem\n",
      "./trimap1/232.jpg file has problem\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pymatting as pym\n",
    " \n",
    "imagepath = './256img_lst/'\n",
    "trimappath = './trimap1'\n",
    "pymtrwpath = './pymatting_outcome_rw1'\n",
    "imagelist = os.listdir(imagepath)\n",
    "trimaplist = os.listdir(trimappath)\n",
    "\n",
    "for filename in imagelist:\n",
    "    try:\n",
    "        image = pym.load_image(imagepath +\"/\"+filename, \"RGB\")\n",
    "        trimap = pym.load_image(trimappath+\"/\"+filename, \"GRAY\")\n",
    "\n",
    "        alpha = pym.estimate_alpha_rw(\n",
    "            image,\n",
    "            trimap,\n",
    "            laplacian_kwargs={},\n",
    "            cg_kwargs={})\n",
    "        pym.save_image(pymtrwpath +\"/\"+filename , alpha)\n",
    "    except:\n",
    "        print(f'{trimappath+\"/\"+filename} file has problem')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
